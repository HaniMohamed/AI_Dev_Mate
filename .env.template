# AI Dev Mate Configuration Template
# Copy this file to .env and modify the values as needed

# Ollama Model Configuration
OLLAMA_MODEL=codellama:7b
OLLAMA_HOST=http://localhost:11434
OLLAMA_TIMEOUT=300
OLLAMA_MAX_RETRIES=3
OLLAMA_RETRY_DELAY=2

# Model Parameters
MAX_TOKENS=4000
TEMPERATURE=0.3

# Git Configuration
GIT_DEFAULT_BRANCH=main

# Logging
LOG_LEVEL=INFO

# Reports Directory
REPORTS_DIR=reports

# Example configurations for different use cases:

# Fast Reviews (Smaller Model)
# OLLAMA_MODEL=codellama:7b
# TEMPERATURE=0.1
# MAX_TOKENS=2000

# High Quality Reviews (Larger Model)
# OLLAMA_MODEL=codellama:34b
# TEMPERATURE=0.2
# MAX_TOKENS=8000
# OLLAMA_TIMEOUT=900

# Remote Ollama Server
# OLLAMA_HOST=http://192.168.1.100:11434
# OLLAMA_MODEL=codellama:13b

# Alternative Models
# OLLAMA_MODEL=llama3.1:8b
# OLLAMA_MODEL=deepseek-coder:6.7b
# OLLAMA_MODEL=qwen2.5-coder:7b